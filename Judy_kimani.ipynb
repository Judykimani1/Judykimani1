{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1cT7gO3IfHZYbhkZ8uzWy48AXdjPxnvgw",
      "authorship_tag": "ABX9TyMaUd+bz0v5nyY60psWWt/1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Judykimani1/Judykimani1/blob/main/Judy_kimani.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install required libraries\n",
        "!pip install llama-index llama-index-embeddings-huggingface llama-index-llms-huggingface bitsandbytes --quiet"
      ],
      "metadata": {
        "id": "vfURL3fKTH4Z"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Import libraries\n",
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from llama_index.core import Document, VectorStoreIndex, StorageContext, Settings\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core.memory import ChatMemoryBuffer\n",
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "\n"
      ],
      "metadata": {
        "id": "CCNLAXV0htew"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: how to mount my dataset from google drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mkqlGHoH_Q5",
        "outputId": "eafac7cf-e827-4f9e-f87c-4e7a397af5a9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load metadata\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/cord19dataset/metadata.csv\", low_memory=False)\n",
        "\n",
        "# Fill missing titles and abstracts with empty strings\n",
        "df[\"title\"] = df[\"title\"].fillna(\"\").str.lower()\n",
        "df[\"abstract\"] = df[\"abstract\"].fillna(\"\").str.lower()\n",
        "\n",
        "# Define keywords\n",
        "smoking_keywords = [\"smoking\", \"tobacco\", \"nicotine\", \"cigarette\", \"vaping\"]\n",
        "covid_keywords = [\"covid\", \"covid-19\", \"sars-cov-2\", \"coronavirus\", \"novel coronavirus\"]\n",
        "\n",
        "# Filter for papers containing both smoking-related and COVID-19-related terms\n",
        "is_smoking_related = df[\"title\"].str.contains(\"|\".join(smoking_keywords)) | df[\"abstract\"].str.contains(\"|\".join(smoking_keywords))\n",
        "is_covid_related = df[\"title\"].str.contains(\"|\".join(covid_keywords)) | df[\"abstract\"].str.contains(\"|\".join(covid_keywords))\n",
        "\n",
        "filtered_df = df[is_smoking_related & is_covid_related]\n",
        "\n",
        "# Save results\n",
        "filtered_df.to_csv(\"filtered_metadata_smoking_covid.csv\", index=False)\n",
        "\n",
        "# Show how many papers matched\n",
        "print(f\"Found {len(filtered_df)} papers related to smoking and COVID-19.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1v3denech28g",
        "outputId": "5457a3fb-4014-40d0-86d9-bbf97b09f368"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 63 papers related to smoking and COVID-19.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pzdmk77w5cA",
        "outputId": "e4401cc0-3450-4cdd-fc67-dfe114e4d367"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['cord_uid', 'sha', 'source_x', 'title', 'doi', 'pmcid', 'pubmed_id', 'license', 'abstract', 'publish_time', 'authors', 'journal', 'Microsoft Academic Paper ID', 'WHO #Covidence', 'has_pdf_parse', 'has_pmc_xml_parse', 'full_text_file', 'url']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = pd.read_csv(\"filtered_metadata_smoking_covid.csv\")\n"
      ],
      "metadata": {
        "id": "QQdmqfVrVw80"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Load filtered metadata\n",
        "df_filtered = pd.read_csv(\"filtered_metadata_smoking_covid.csv\")  # Your keyword-filtered metadata\n",
        "df_filtered = df_filtered[df_filtered['full_text_file'].notnull()]"
      ],
      "metadata": {
        "id": "ElYXuqhNXaPe"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: Set up the LLM agent\n",
        "llm = HuggingFaceLLM(\n",
        "    model_name=\"colesmcintosh/Llama-3.2-1B-Instruct-Mango\",\n",
        "    tokenizer_name=\"colesmcintosh/Llama-3.2-1B-Instruct-Mango\",\n",
        "    context_window=2048,\n",
        "    max_new_tokens=256,\n",
        "    device_map=\"cuda\",\n",
        "    generate_kwargs={\"temperature\": 0.7, \"do_sample\": True},\n",
        ")\n",
        "Settings.llm = llm\n",
        "\n",
        "# Use index_storage_dir instead of persist_dir\n",
        "storage_context = StorageContext.from_defaults(persist_dir=index_storage_dir)\n",
        "index = load_index_from_storage(storage_context)\n",
        "\n",
        "chat_engine = index.as_chat_engine(\n",
        "    chat_mode=\"context\",\n",
        "    memory=ChatMemoryBuffer.from_defaults(token_limit=3000),\n",
        "    system_prompt=\"You are a helpful medical assistant. You only answer based on CORD-19 papers related to COVID-19 and smoking.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5fBYttjYqNA",
        "outputId": "7f586a91-7930-4bf8-b06e-36729b44e79d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:llama_index.llms.huggingface.base:The model `unsloth/llama-3.2-1b-instruct-bnb-4bit` and tokenizer `colesmcintosh/Llama-3.2-1B-Instruct-Mango` are different, please ensure that they are compatible.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: Create the vector store index\n",
        "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\", device=\"cuda\")\n",
        "Settings.embed_model = embed_model\n",
        "Settings.llm = None\n",
        "documents = [Document(text=row[\"abstract\"]) for _, row in filtered_df.iterrows()]\n",
        "\n",
        "index_storage_dir = \"/content/drive/MyDrive/cord19dataset/cord19_index\"\n",
        "if not os.path.exists(index_storage_dir):\n",
        "    index = VectorStoreIndex.from_documents(documents)\n",
        "    index.storage_context.persist(persist_dir=index_storage_dir)\n",
        "else:\n",
        "    print(\"Index already exists.\")"
      ],
      "metadata": {
        "id": "Xld0G2q6YRUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "919798a5-fe9e-47d1-fd07-66256dfc848c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM is explicitly disabled. Using MockLLM.\n",
            "Index already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fxbIvLAllrSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Query loop\n",
        "while True:\n",
        "    query = input(\"You: \")\n",
        "    if query.lower() == \"quit\":\n",
        "        break\n",
        "    response = chat_engine.chat(query)\n",
        "    print(f\"Agent: {response.response}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "LdG8Dx_yY65g",
        "outputId": "60896655-3c80-4162-8233-7e12c1bdfa45"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: what is smoking\n",
            "Agent: Smoking refers to the act of burning tobacco or tobacco products, such as cigarettes, cigars, and pipes. Smoking can also refer to the act of inhaling the smoke from these products. Smoking is a major risk factor for many diseases, including lung cancer, heart disease, and other respiratory problems.\n",
            "You: difference between nicotine and tobacco\n",
            "Agent: Nicotine is the addictive substance found in tobacco products, while tobacco is the plant from which it is derived. Tobacco refers to the dried leaves of the tobacco plant, while nicotine is the chemical compound that is present in tobacco.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-81e9c888d491>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# STEP 7: Query loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"quit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "66uNkvPOLu2c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}